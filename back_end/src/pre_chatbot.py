import os
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_pinecone import PineconeVectorStore
from langchain.retrievers import EnsembleRetriever

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ë° ì„¤ì •
pinecone_api_key = os.environ.get("PINECONE_API_KEY")
embedding_upstage = UpstageEmbeddings(model="embedding-query")
index_name = "samsung"

# 1. Pineconeì—ì„œ ë²¡í„° ì €ì¥ì†Œ ë¶ˆëŸ¬ì˜¤ê¸°
def load_vectorstore(index_name="samsung"):
    vectorstore = PineconeVectorStore(
        index_name=index_name,
        embedding=embedding_upstage
    )
    return vectorstore

# 2. ê²€ìƒ‰ê¸° ì„¤ì •
def setup_retrievers(vectorstore):
    # Dense Retriever (Pinecone)
    retriever = vectorstore.as_retriever(
        search_type='mmr',
        search_kwargs={"k": 10}
    )
    
    # Ensemble Retriever (Denseë§Œ ì‚¬ìš©)
    ensemble_retriever = EnsembleRetriever(
        retrievers=[retriever],
        weights=[1.0]  # Dense Retrieverì— ê°€ì¤‘ì¹˜ 100%
    )
    return ensemble_retriever

# 3. ì±—ë´‡ ì‘ë‹µ ìƒì„±
def generate_response(ensemble_retriever, query):
    result_docs = ensemble_retriever.invoke(query)
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
                ë‹¹ì‹ ì€ ì·¨ì—… ì»¨ì„¤í„´íŠ¸ë¡œì„œ ì „ë¬¸ì„±ê³¼ ê³µê° ëŠ¥ë ¥ì„ ê°–ì¶˜ ì±—ë´‡ì…ë‹ˆë‹¤. 
                ì‚¬ìš©ìë“¤ì—ê²Œ ì›í•˜ëŠ” ì§ë¬´ì™€ ê¸°ì—…ì— ëŒ€í•´ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ë©°, 
                ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì—… ì¶”ì²œê³¼ ìƒì„¸í•œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ê³ , ê·¼ê±°ë¥¼ í•¨ê»˜ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

                ë‹¹ì‹ ì˜ ì—­í• :
                1. ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì§ë¬´ë‚˜ ì§ì¢…ì„ ì œì‹œí•˜ë©´, ê´€ë ¨ ê¸°ì—…ì„ ì¶”ì²œí•˜ê³  í•´ë‹¹ ê¸°ì—…ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
                   (ì˜ˆ: ì¬ë¬´ ìƒíƒœ, ìµœê·¼ ì†Œì‹, ì±„ìš© ê³µê³  ë“±)
                2. ì‚¬ìš©ìê°€ íŠ¹ì • ê¸°ì—…ì„ ì–¸ê¸‰í•˜ë©´, í•´ë‹¹ ê¸°ì—…ì— ëŒ€í•´ ê°€ëŠ¥í•œ ëª¨ë“  ì •ë³´ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
                3. ë‹µë³€ì€ í•­ìƒ ëª…í™•í•˜ê³ , ì •í™•í•˜ë©°, ì‚¬ìš©ìê°€ ë°”ë¡œ í–‰ë™ì— ì˜®ê¸¸ ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.
                4. ë°ì´í„°ì— ê¸°ë°˜í•œ ë‹µë³€ì´ ë¶ˆê°€ëŠ¥í•  ê²½ìš°, ì •ì¤‘íˆ ì•ˆë‚´í•˜ê³  ë‹¤ë¥¸ ë°©ë²•ì„ ì œì•ˆí•˜ì„¸ìš”.

                í•­ìƒ ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•œ íƒœë„ë¡œ ë‹µë³€í•˜ë©°, ì‚¬ìš©ìê°€ ì·¨ì—… ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆë„ë¡ ì§„ì‹¬ìœ¼ë¡œ ë•ëŠ” ëª¨ìŠµì„ ë³´ì—¬ì£¼ì„¸ìš”.
                ---
                CONTEXT:
                {context}
                """
            ),
            ("human", "{input}"),
        ]
    )
    llm = ChatUpstage()
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({"context": result_docs, "input": query})
    return response

# 4. ë©”ì¸ í•¨ìˆ˜
def main():
    # Pineconeì—ì„œ ë²¡í„° ì €ì¥ì†Œ ë¶ˆëŸ¬ì˜¤ê¸°
    vectorstore = load_vectorstore(index_name)
    print("âœ… Pinecone ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì™„ë£Œ.")
    
    # ê²€ìƒ‰ê¸° ì„¤ì •
    ensemble_retriever = setup_retrievers(vectorstore)
    print("âœ… ê²€ìƒ‰ê¸° ì„¤ì • ì™„ë£Œ.")
    
    # ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
    query = input("ğŸ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    response = generate_response(ensemble_retriever, query)
    print("ğŸ¤– ì±—ë´‡ ì‘ë‹µ:")
    print(response)

if __name__ == "__main__":
    main()